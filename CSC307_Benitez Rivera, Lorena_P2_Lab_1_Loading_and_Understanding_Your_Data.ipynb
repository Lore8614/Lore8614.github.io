{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 1: Loading and Understanding Your Data",
      "provenance": [],
      "collapsed_sections": [
        "JndnmDMp66FL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lore8614/Lore8614.github.io/blob/master/CSC307_Benitez%20Rivera%2C%20Lorena_P2_Lab_1_Loading_and_Understanding_Your_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JndnmDMp66FL"
      },
      "source": [
        "#### Copyright 2018 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "hMqWDc_m6rUC",
        "colab": {}
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lab_objectives"
      },
      "source": [
        "# Lab 1: Loading and Understanding Your Data\n",
        "** Learning Objectives **\n",
        "* Learn the basics of reading data, data cleaning and handling missing data using Pandas.\n",
        "* Learn how to visualize data with a scatter plot.\n",
        "* Use Numpy to generate the line minimizing squared loss.\n",
        "* Explore visually the difference in the model when replacing missing items by 0s versus the mean value for that feature."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "import_text"
      },
      "source": [
        "### Imports\n",
        "In this first cell, we'll import some libraries, including  [Pandas](http://pandas.pydata.org/), which is a package we use for reading in our data, exploring our data and doing some basic processing. Run this cell to execute the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "colab_type": "code",
        "id": "import_code",
        "colab": {}
      },
      "source": [
        "import fnmatch\n",
        "import math\n",
        "\n",
        "from IPython import display\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.data import Dataset\n",
        "\n",
        "# This line increasing the amount of logging when there is an error.  You can\n",
        "# remove it if you want less logging\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "print(\"Done with the imports.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pandas_text"
      },
      "source": [
        "### Set up Pandas Options\n",
        "\n",
        "Next we set up some options to control how items are displayed and the maximum number of rows to show when displaying a table.  Feel free to change this setup to whatever you'd like.\n",
        "\n",
        "As illustrated below, in colab you can define code cells that do not generate any output. In fact, the first cell would also have been that way except for the `print` statement at the end added just to help illustrate this aspect of colab. If at any point you are not sure if a cell is successfully running, you can add a print statement, but that should not be necessary since you can visually see when the cell is done running when the arrow is showing again. Also note that when you select the next cell the number showing the execution order of the cell appears."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pandas_code",
        "colab": {}
      },
      "source": [
        "# Set the output display to have two digits for decimal places, for display\n",
        "# readability only and limit it to printing 15 rows.\n",
        "pd.options.display.float_format = '{:.2f}'.format\n",
        "pd.options.display.max_rows = 15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "data_set_text_long_description"
      },
      "source": [
        "### Data Set\n",
        "This lab will use a data set from 1985 Ward's Automotive Yearbook that is part of the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets) under [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/automobile).  You can find a description of the data at [https://archive.ics.uci.edu/ml/datasets/automobile](https://archive.ics.uci.edu/ml/datasets/automobile).  Since this data set is provided as a comma separated file without a header row, we provide column headers when loading it with Pandas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "load_auto_data_set_text"
      },
      "source": [
        "### Loading and Randomizing the Data\n",
        "Load the data using the column names from [Automobile Data Set](https://archive.ics.uci.edu/ml/datasets/automobile). When using SGD (stochastic graident descent) for training it is important that **each batch is a random sample of the data** so that the gradient computed is representative.  While there appears to be no order to this data set, it is always good practice to shuffle the data to be in a random order.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "load_auto_data_set_code",
        "colab": {}
      },
      "source": [
        "# Provide the names for the columns since the CSV file with the data does\n",
        "# not have a header row.\n",
        "cols = ['symboling', 'losses', 'make', 'fuel-type', 'aspiration', 'num-doors',\n",
        "        'body-style', 'drive-wheels', 'engine-location', 'wheel-base',\n",
        "        'length', 'width', 'height', 'weight', 'engine-type', 'num-cylinders',\n",
        "        'engine-size', 'fuel-system', 'bore', 'stroke', 'compression-ratio',\n",
        "        'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n",
        "\n",
        "\n",
        "# Load in the data from a CSV file that is comma seperated.\n",
        "car_data = pd.read_csv('https://storage.googleapis.com/ml_universities/cars_dataset/cars_data.csv',\n",
        "                        sep=',', names=cols, header=None, encoding='latin-1')\n",
        "\n",
        "# We'll then randomize the data, just to be sure not to get any pathological\n",
        "# ordering effects that might harm the performance of Stochastic Gradient\n",
        "# Descent.\n",
        "car_data = car_data.reindex(np.random.permutation(car_data.index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "examine_data_text"
      },
      "source": [
        "### Examine the Data\n",
        "\n",
        "It's a good idea to get to know your data a little bit before you work with it. Let's look at the header row and the first 10 rows of data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "examine_data_code",
        "colab": {}
      },
      "source": [
        "car_data[1:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view_data_statistics_text"
      },
      "source": [
        "### Look at Some Basic Statistics About the Data\n",
        "We'll print out a quick summary of a few useful statistics on each column. This will include things like mean, standard deviation, max, min, and various quantiles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "view_data_statistics_code",
        "colab": {}
      },
      "source": [
        "car_data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "handling_missing_data_text"
      },
      "source": [
        "### Handling Missing Data Entries\n",
        "Why are some columns such as the price and losses not showing in the summary column?  If we look at the data more carefuly, we'll see that a \"?\" was used in this data set to indicate that a value is unknown.\n",
        "\n",
        "Pandas provices a method [to_numeric](http://pandas.pydata.org/pandas-docs/version/0.18.1/generated/pandas.to_numeric.html) that converts a column to be numeric. There are three options about how to handle errors (entries that are not numeric) of which 'coerce' is what we want to use in this situation, since it converts those entries to pandas representation `NaN` for \"not a number\".\n",
        "\n",
        "Notice now when you use `describe` to see the statistics for the entries that are a number, the count indicates how many entries had a number (not `NaN`) for that column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "handling_missing_data_code",
        "colab": {}
      },
      "source": [
        "car_data['price'] = pd.to_numeric(car_data['price'], errors='coerce')\n",
        "car_data['horsepower'] = pd.to_numeric(car_data['horsepower'], errors='coerce')\n",
        "car_data['peak-rpm'] = pd.to_numeric(car_data['peak-rpm'], errors='coerce')\n",
        "car_data['city-mpg'] = pd.to_numeric(car_data['city-mpg'], errors='coerce')\n",
        "car_data['highway-mpg'] = pd.to_numeric(car_data['highway-mpg'], errors='coerce')\n",
        "car_data['losses'] = pd.to_numeric(car_data['losses'], errors='coerce')\n",
        "car_data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "replacing_nan_by_0_text"
      },
      "source": [
        "### Replacing NAN by zero\n",
        "When training a linear model using features that is numerical, we **cannot have `NaN` (doing so would cause overflow when training)**. Here we replace `NaN` (which corresponding to where we had missing entries) by 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "replacing_nan_by_0_code",
        "colab": {}
      },
      "source": [
        "# Replace nan by 0 storing the solution in the same table (`inplace')\n",
        "car_data.fillna(0, inplace=True)\n",
        "car_data.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "scatter_plot_text"
      },
      "source": [
        "### Using a Scatter Plot to Visualize the Data\n",
        "\n",
        "We will begin by trying to predict the price using the horsepower.  Because we just have a single feature we can visualize the raw data using a scatter plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "scatter_plot_code",
        "colab": {}
      },
      "source": [
        "INPUT_FEATURE = \"horsepower\"\n",
        "LABEL = \"price\"\n",
        "\n",
        "plt.ylabel(LABEL)\n",
        "plt.xlabel(INPUT_FEATURE)\n",
        "plt.scatter(car_data[INPUT_FEATURE], car_data[LABEL], c='black')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "polyfit_text"
      },
      "source": [
        "###Using Numpy polyfit to Find the Line that Minimizes RMSE\n",
        "For the task of finding a line that minimizes the squared error with respect to a set of points, using SGD is not the most efficient method but it will be useful in that it can be applied to much more complex problems.  As a tool to help see what the optimal solution looks like we wil use `polyfit` to compute the optimal solution and then add that to our plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "polyfit_code",
        "colab": {}
      },
      "source": [
        "x = car_data[INPUT_FEATURE]\n",
        "y = car_data[LABEL]\n",
        "opt = np.polyfit(x, y, 1)\n",
        "y_pred = opt[0] * x + opt[1]\n",
        "opt_rmse = math.sqrt(metrics.mean_squared_error(y_pred, y))\n",
        "slope = opt[0]\n",
        "bias = opt[1]\n",
        "print(\"Optimal RMSE =\", opt_rmse, \"for solution\", opt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "line_in_scatter_plot_text"
      },
      "source": [
        "###Visualizing a Linear Model Using a Scatter Plot\n",
        "\n",
        "When training a linear regression model over a single variable, a really nice thing to be able to do is to show the model (which is just a line) as part of the scatter plot. That really helps you see how well the model fits the data. Just looking at the loss (RMSE here) doesn't really indicate how good the model is. Sometimes you want to show several models on the same scatter plot to compare them so we allow slopes, biases, and model_names to all be lists. They should be of the same size giving the weight (slope), bias, and name (to use in the legend) for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "scatter_plot_function",
        "colab": {}
      },
      "source": [
        "def scatter_plot(features, targets, slopes=[], biases=[], model_names=[]):\n",
        "  \"\"\" Creates a scatter plot of input_feature vs target along with the models.\n",
        "  \n",
        "  Args:\n",
        "    features: list of the input features\n",
        "    targets: list of targets\n",
        "    slopes: list of model weight (slope) \n",
        "    bias: list of model bias (same size as slopes)\n",
        "    model_names: list of model_names to use for legend (same size as slopes)\n",
        "  \"\"\"      \n",
        "  # Define some colors to use that go from blue towards red\n",
        "  colors = [cm.coolwarm(x) for x in np.linspace(0, 1, len(slopes))]\n",
        "  \n",
        "  # Generate the Scatter plot\n",
        "  plt.ylabel(\"target\")\n",
        "  plt.xlabel(\"input feature\")\n",
        "  plt.scatter(features, targets, color='black', label=\"\")\n",
        "  \n",
        "  # Add the lines corresponding to the provided models\n",
        "  for i in range (0, len(slopes)):\n",
        "    y_0 = slopes[i] * features.min() + biases[i]\n",
        "    y_1 = slopes[i] * features.max() + biases[i]\n",
        "    plt.plot([features.min(), features.max()], [y_0, y_1],\n",
        "             label=model_names[i], color=colors[i])\n",
        "  if (len(model_names) > 0):\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "generate_scatter_plot_with_line",
        "colab": {}
      },
      "source": [
        "scatter_plot(car_data[INPUT_FEATURE], car_data[LABEL],\n",
        "             [slope], [bias], [\"optimal model\"])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise_create_new_scatter_plot"
      },
      "source": [
        "## Exercise: Create a Scatter Plot for Different Features (1 Point)\n",
        "\n",
        "Create a scatter plot with price as the input feature and losses as the label where the line optimizing the squared loss is shown.  We've gotten you started.  You just need to copy the appropriate lines from above.  **Save the slope and bias from this line to be used in a later exercise.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "exercise_create_new_scatter_plot_code_block",
        "colab": {}
      },
      "source": [
        "INPUT_FEATURE = \"price\"\n",
        "LABEL = \"losses\"\n",
        "\n",
        "# Fill in the rest of this block."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "exercise_what_did_you_see"
      },
      "source": [
        "## Exercise: Explain what you see (1 point)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "exercise_what_did_you_see_code_block",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Explain why you are seeing so many points along the line y=0.\n",
        "\n",
        "TYPE YOUR ANSWER IN THIS COMMENT\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "handling_missing_data_options_text"
      },
      "source": [
        "##Exercise: Explore Options to Handle Missing Data (3 Points)\n",
        "\n",
        "In this exercise you will explore alternate ways to handle missing data. When training a linear model using features that are numerical, we **cannot have `NaN` (doing so would cause overflow when training)**. One option is to just discard any rows with any missing entries but often this would not leave enough data.  Here we explore ways to handle the missing data without just discarding it.\n",
        "\n",
        "Note that when you get a column of a dataframe (e.g. car_data[\"price']), you get a `Series`.  Read [http://pandas.pydata.org/pandas-docs/version/0.18.1/api.html#computations-descriptive-stats](http://pandas.pydata.org/pandas-docs/version/0.18.1/api.html#computations-descriptive-stats) and think about if you see any statistics for a column that might make a better choice than 0 for filling in the missing entries.What do you think would work best?\n",
        "\n",
        "Modify the code to use the function you selected to replace missing data instead of just using 0. Look at both the scatter plots and the lines minimizing RMSEs of both outputs. Feel free to show multiple options as a tool to help you explain your choice of which you think is best. What option do you think is best and why?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "handling_missing_data_options_code",
        "colab": {}
      },
      "source": [
        "# Load in the data from a CSV file that is comma seperated.\n",
        "car_data_v2 = pd.read_csv('https://storage.googleapis.com/ml_universities/cars_dataset/cars_data.csv',\n",
        "                           sep=',', names=cols, header=None, encoding='latin-1')\n",
        "car_data_v2['price'] = pd.to_numeric(car_data_v2['price'], errors='coerce')\n",
        "car_data_v2['losses'] = pd.to_numeric(car_data_v2['losses'], errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "exercise_how_to_fill_in_nan",
        "colab": {}
      },
      "source": [
        "# Fill in what you want to do with the nan here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "exercise_create_scatter_plot_for_na_options",
        "colab": {}
      },
      "source": [
        "# Create a scatter plot with the model from above (when NA replaced by 0) and at least one other option."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "exercise_which_option_was_best",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "What option you think is best and why?\n",
        "\n",
        "PUT YOUR ANSWER HERE\n",
        "\n",
        "\n",
        "\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}